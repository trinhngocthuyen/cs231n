{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "deletable": true
   },
   "source": [
    "# Dropout\n",
    "Dropout [1] is a technique for regularizing neural networks by randomly setting some features to zero during the forward pass. In this exercise you will implement a dropout layer and modify your fully-connected network to optionally use dropout.\n",
    "\n",
    "[1] Geoffrey E. Hinton et al, \"Improving neural networks by preventing co-adaptation of feature detectors\", arXiv 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def logdiff(x, y, prefix='', h=1e-6):\n",
    "    rel_error = np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "    matched = np.alltrue(np.abs(x - y) < h)\n",
    "    print('%s relative error %.3e. Matched: %s' % (prefix, rel_error, matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "deletable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\ny_train:  (49000,)\nX_val:  (1000, 3, 32, 32)\ny_val:  (1000,)\nX_test:  (1000, 3, 32, 32)\ny_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "    print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "deletable": true
   },
   "source": [
    "# Dropout forward pass\n",
    "In the file `cs231n/layers.py`, implement the forward pass for dropout. Since dropout behaves differently during training and testing, make sure to implement the operation for both modes.\n",
    "\n",
    "Once you have done so, run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "deletable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests with p =  0.3\nMean of input:  10.0002078785\nMean of train-time output:  10.0350727971\nMean of test-time output:  10.0002078785\nFraction of train-time output set to zero:  0.699124\nFraction of test-time output set to zero:  0.0\n\nRunning tests with p =  0.6\nMean of input:  10.0002078785\nMean of train-time output:  9.97779296231\nMean of test-time output:  10.0002078785\nFraction of train-time output set to zero:  0.401252\nFraction of test-time output set to zero:  0.0\n\nRunning tests with p =  0.75\nMean of input:  10.0002078785\nMean of train-time output:  9.9951159931\nMean of test-time output:  10.0002078785\nFraction of train-time output set to zero:  0.25062\nFraction of test-time output set to zero:  0.0\n\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(500, 500) + 10\n",
    "\n",
    "for p in [0.3, 0.6, 0.75]:\n",
    "    out, _ = dropout_forward(x, {'mode': 'train', 'p': p})\n",
    "    out_test, _ = dropout_forward(x, {'mode': 'test', 'p': p})\n",
    "\n",
    "    print('Running tests with p = ', p)\n",
    "    print('Mean of input: ', x.mean())\n",
    "    print('Mean of train-time output: ', out.mean())\n",
    "    print('Mean of test-time output: ', out_test.mean())\n",
    "    print('Fraction of train-time output set to zero: ', (out == 0).mean())\n",
    "    print('Fraction of test-time output set to zero: ', (out_test == 0).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "deletable": true
   },
   "source": [
    "# Dropout backward pass\n",
    "In the file `cs231n/layers.py`, implement the backward pass for dropout. After doing so, run the following cell to numerically gradient-check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "deletable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx relative error 1.893e-11. Matched: True\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10) + 10\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dropout_param = {'mode': 'train', 'p': 0.8, 'seed': 123}\n",
    "out, cache = dropout_forward(x, dropout_param)\n",
    "dx = dropout_backward(dout, cache)\n",
    "dx_num = eval_numerical_gradient_array(lambda xx: dropout_forward(xx, dropout_param)[0], x, dout)\n",
    "\n",
    "logdiff(dx, dx_num, prefix='dx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "deletable": true
   },
   "source": [
    "# Fully-connected nets with Dropout\n",
    "In the file `cs231n/classifiers/fc_net.py`, modify your implementation to use dropout. Specificially, if the constructor the the net receives a nonzero value for the `dropout` parameter, then the net should add dropout immediately after every ReLU nonlinearity. After doing so, run the following to numerically gradient-check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "deletable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with dropout =  0\nInitial loss:  2.30047908977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0 relative error 1.484e-07. Matched: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 relative error 2.212e-05. Matched: True\nW2 relative error 3.527e-07. Matched: True\nb0 relative error 5.376e-09. Matched: True\nb1 relative error 2.086e-09. Matched: True\nb2 relative error 5.796e-11. Matched: True\n\nRunning check with dropout =  0.25\nInitial loss:  2.29243250883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0 relative error 2.742e-08. Matched: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 relative error 2.979e-09. Matched: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 relative error 4.286e-09. Matched: True\nb0 relative error 7.777e-10. Matched: True\nb1 relative error 3.360e-10. Matched: True\nb2 relative error 1.654e-10. Matched: True\n\nRunning check with dropout =  0.5\nInitial loss:  2.30427592208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0 relative error 3.110e-07. Matched: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 relative error 1.844e-08. Matched: True\nW2 relative error 5.352e-08. Matched: True\nb0 relative error 2.577e-08. Matched: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 relative error 2.989e-09. Matched: True\nb2 relative error 9.544e-11. Matched: True\n\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for dropout in [0, 0.25, 0.5]:\n",
    "    print('Running check with dropout = ', dropout)\n",
    "    model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                              weight_scale=5e-2, dtype=np.float64,\n",
    "                              dropout=dropout, seed=123)\n",
    "\n",
    "    loss, grads = model.loss(X, y)\n",
    "    print('Initial loss: ', loss)\n",
    "\n",
    "    for name in sorted(grads):\n",
    "        f = lambda _: model.loss(X, y)[0]\n",
    "        grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "        logdiff(grad_num, grads[name], prefix=name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "deletable": true
   },
   "source": [
    "# Regularization experiment\n",
    "As an experiment, we will train a pair of two-layer networks on 500 training examples: one will use no dropout, and one will use a dropout probability of 0.75. We will then visualize the training and validation accuracies of the two networks over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "collapsed": true,
    "editable": true,
    "deletable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n(Iteration 1 / 125) loss: 7.856644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 0 / 25) train acc: 0.274000; val_acc: 0.192000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1 / 25) train acc: 0.388000; val_acc: 0.248000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2 / 25) train acc: 0.490000; val_acc: 0.282000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3 / 25) train acc: 0.538000; val_acc: 0.243000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4 / 25) train acc: 0.656000; val_acc: 0.284000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5 / 25) train acc: 0.724000; val_acc: 0.274000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6 / 25) train acc: 0.732000; val_acc: 0.278000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7 / 25) train acc: 0.818000; val_acc: 0.253000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8 / 25) train acc: 0.868000; val_acc: 0.278000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9 / 25) train acc: 0.890000; val_acc: 0.291000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10 / 25) train acc: 0.884000; val_acc: 0.260000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 11 / 25) train acc: 0.944000; val_acc: 0.276000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 12 / 25) train acc: 0.946000; val_acc: 0.284000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 13 / 25) train acc: 0.948000; val_acc: 0.286000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 14 / 25) train acc: 0.944000; val_acc: 0.287000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 15 / 25) train acc: 0.982000; val_acc: 0.292000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 16 / 25) train acc: 0.980000; val_acc: 0.278000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 17 / 25) train acc: 0.986000; val_acc: 0.280000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 18 / 25) train acc: 0.986000; val_acc: 0.305000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 19 / 25) train acc: 0.988000; val_acc: 0.306000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 20 / 25) train acc: 0.994000; val_acc: 0.306000\n(Iteration 101 / 125) loss: 0.000209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 21 / 25) train acc: 0.996000; val_acc: 0.302000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 22 / 25) train acc: 1.000000; val_acc: 0.298000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 23 / 25) train acc: 1.000000; val_acc: 0.289000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 24 / 25) train acc: 0.998000; val_acc: 0.297000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 25 / 25) train acc: 1.000000; val_acc: 0.294000\n0.75\n(Iteration 1 / 125) loss: 11.299055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 0 / 25) train acc: 0.246000; val_acc: 0.181000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1 / 25) train acc: 0.440000; val_acc: 0.273000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2 / 25) train acc: 0.514000; val_acc: 0.280000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3 / 25) train acc: 0.572000; val_acc: 0.252000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4 / 25) train acc: 0.680000; val_acc: 0.270000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5 / 25) train acc: 0.720000; val_acc: 0.298000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6 / 25) train acc: 0.748000; val_acc: 0.301000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7 / 25) train acc: 0.794000; val_acc: 0.297000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8 / 25) train acc: 0.830000; val_acc: 0.287000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9 / 25) train acc: 0.890000; val_acc: 0.299000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10 / 25) train acc: 0.866000; val_acc: 0.318000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 11 / 25) train acc: 0.926000; val_acc: 0.284000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 12 / 25) train acc: 0.946000; val_acc: 0.303000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 13 / 25) train acc: 0.938000; val_acc: 0.295000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 14 / 25) train acc: 0.954000; val_acc: 0.294000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 15 / 25) train acc: 0.948000; val_acc: 0.279000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 16 / 25) train acc: 0.980000; val_acc: 0.302000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 17 / 25) train acc: 0.974000; val_acc: 0.324000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 18 / 25) train acc: 0.982000; val_acc: 0.297000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 19 / 25) train acc: 0.990000; val_acc: 0.288000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 20 / 25) train acc: 0.978000; val_acc: 0.270000\n(Iteration 101 / 125) loss: 0.798170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 21 / 25) train acc: 0.990000; val_acc: 0.289000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 22 / 25) train acc: 0.994000; val_acc: 0.301000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 23 / 25) train acc: 0.996000; val_acc: 0.303000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 24 / 25) train acc: 0.994000; val_acc: 0.301000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 25 / 25) train acc: 0.996000; val_acc: 0.310000\n"
     ]
    }
   ],
   "source": [
    "# Train two identical nets, one with dropout and one without\n",
    "np.random.seed(231)\n",
    "num_train = 500\n",
    "small_data = {\n",
    "    'X_train': data['X_train'][:num_train],\n",
    "    'y_train': data['y_train'][:num_train],\n",
    "    'X_val': data['X_val'],\n",
    "    'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "dropout_choices = [0, 0.75]\n",
    "for dropout in dropout_choices:\n",
    "    model = FullyConnectedNet([500], dropout=dropout)\n",
    "    print(dropout)\n",
    "\n",
    "    solver = Solver(model, small_data,\n",
    "                    num_epochs=25, batch_size=100,\n",
    "                    update_rule='adam',\n",
    "                    optim_config={\n",
    "                        'learning_rate': 5e-4,\n",
    "                    },\n",
    "                    verbose=True, print_every=100)\n",
    "    solver.train()\n",
    "    solvers[dropout] = solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "deletable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAJJCAYAAABlF8tTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEEKfqrIQe/3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107675d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train and validation accuracies of the two models\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for dropout in dropout_choices:\n",
    "    solver = solvers[dropout]\n",
    "    train_accs.append(solver.train_acc_history[-1])\n",
    "    val_accs.append(solver.val_acc_history[-1])\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "for dropout in dropout_choices:\n",
    "    plt.plot(solvers[dropout].train_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Train accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "for dropout in dropout_choices:\n",
    "    plt.plot(solvers[dropout].val_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Val accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.gcf().set_size_inches(12, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692307692308\ntrain-train (with - without): [-0.006 -0.006 -0.004 -0.004 -0.004]\ntrain-val (without dropout): [ 0.694  0.702  0.711  0.701  0.706]\ntrain-val (WITH dropout): [ 0.701  0.693  0.693  0.693  0.686]\n"
     ]
    }
   ],
   "source": [
    "val_acc_without_dropout = np.array(solvers[dropout_choices[0]].val_acc_history)\n",
    "val_acc_with_dropout= np.array(solvers[dropout_choices[1]].val_acc_history)\n",
    "\n",
    "train_acc_without_dropout = np.array(solvers[dropout_choices[0]].train_acc_history)\n",
    "train_acc_with_dropout= np.array(solvers[dropout_choices[1]].train_acc_history)\n",
    "\n",
    "print((val_acc_with_dropout > val_acc_without_dropout).mean())\n",
    "print('train-train (with - without):', \n",
    "      (train_acc_with_dropout - train_acc_without_dropout)[-5:])\n",
    "print('train-val (without dropout):', \n",
    "      (train_acc_without_dropout - val_acc_without_dropout)[-5:])\n",
    "print('train-val (WITH dropout):', \n",
    "      (train_acc_with_dropout - val_acc_with_dropout)[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "deletable": true
   },
   "source": [
    "# Question\n",
    "Explain what you see in this experiment. What does it suggest about dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "deletable": true
   },
   "source": [
    "# Answer\n",
    "Observing figures of the last 5 epochs, we see that using dropout generally produces higher validation accuracy. Besides, training accuracy does not drop much when using dropout (by ~ 0.5%).\n",
    "Therefore, the gap between training accuracy and validation accuracy is lessen thanks to it. This gives us the intuition that dropout plays the very same role as _regularization_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2",
   "language": "python"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "name": "python",
   "file_extension": ".py",
   "version": "2.7.12+",
   "pygments_lexer": "ipython2",
   "codemirror_mode": {
    "version": 2.0,
    "name": "ipython"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}